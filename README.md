# 김승빈(Kim Seung Bin) 👋
- E-mail: kimho1wq@naver.com
- Github: https://github.com/kimho1wq

## 기술 스택
- Java, Spring, Python, Pytorch, MySQL, Git, Redis, Kafka, Docker, Flutter, Jenkins

## 프로젝트
#### - [Java 기반 API 서버 개발과 AI 모델을 이용하여 오디오 메타 정보를 추출하는 플로우 구축](https://github.com/kimho1wq/audio-meta) (2021-01 ~ 2022-03)
- 프로젝트 내용
  -	[instrumentalness, liveness 등 오디오 메타 정보](https://developer.spotify.com/documentation/web-api/reference/get-audio-features) 구축하고 이를 생성하는 AI 모델을 개발
  -	메타 정보를 서비스에 사용하기 위해 [Torchserve](https://github.com/pytorch/serve)를 이용하여 서빙
- 프로젝트 기여도
  -	모델 학습을 위한 프로세스 구축 및 개발
  -	Torchserve를 이용한 AI 모델 서빙 프로세스 설계 및 개발
  -	Spring 프레임워크를 사용하여 Java 기반 API 서버 개발 
- 프로젝트 성과
  -	AI 모델을 도입하여 기존 신호처리 기반 메타정보 성능 대비 30%의 성능 향상
  -	새로운 모델 서빙 프로세스 설계 및 개발


#### - [AI RUSH 2020](https://github.com/kimho1wq/AIRUSH-2020) (2020.08 ~ 2020.09)
- 프로젝트 내용
  -	네이버에서 주최하는 AI Modeling Challenge
  -	Music Classification을 위한 AI 모델링 수행
  -	Speaker Diarization을 위한 AI 모델링 수행
- 프로젝트 기여도
  -	1D 데이터의 특성을 이용한 CRNN 모델을 구현
  -	Attention map을 이용하여 데이터 Scaling 적용
  -	RexNeXt, SpeakerNet 등 다양한 모델 구축 후 적용
  -	최신 기법의 아이디어를 논문을 통해 조사 및 적용
- 프로젝트 성과
  -	기존 모델 대비 최대 60%의 성능을 향상 시키는 모델 생성 및 서비스에 적용
  -	[음성 화자인식, 음원 그레이스 노트 무드 태그 분류, 음원 스테이션 분류 Task에서 수상](https://github.com/kimho1wq/kimho1wq/blob/main/AIRUSH2020/Final%20Ranking.pdf)


#### - [로봇용 free-running 임베디드 자연어 대화음성인식을 위한 원천기술 개발](https://github.com/kimho1wq/SegmentAggregation) (2019.05 ~ 2020.07)
- 프로젝트 내용
  -	Pytorch를 이용하여 화자인증 시스템 구축
  -	짧은 발성에 대한 성능보상 기법을 화자인증 시스템에 적용
- 프로젝트 기여도
  -	화자인증을 위한 베이스라인 시스템 구축
  -	발성의 길이에 따른 시스템의 동일 화자 오류율 측정
  -	Teacher-student learning 등 최신 기법의 아이디어를 논문을 통해 조사 후 짧은 발성 보상에 적용
- 프로젝트 성과
  -	짧은 발성에 의한 성능 저하에 대해 시스템의 인식률을 45% 보상하는 새로운 방법 제안
  -	논문 작성 : [Segment Aggregation for short utterances speaker verification using raw waveforms](https://www.isca-speech.org/archive_v0/Interspeech_2020/pdfs/1564.pdf)


#### - [Voice Cloning TTS를 위한 화자 인식 알고리즘 개발](https://github.com/Jungjee/RawNet) (2019.11 ~ 2020.05)
- 프로젝트 내용
  -	TTS를 위한 화자 인증 시스템 구축
  -	최신 기법의 아이디어를 논문을 통해 조사 및 적용
  -	다양한 음성 특징 벡터 비교 후 적용
- 프로젝트 기여도
  -	Pytorch를 이용하여 화자인증을 위한 베이스라인 시스템 구축
  -	베이스라인 시스템의 성능을 높이기 위한 attention 기법을 적용
  -	Convolutional block attention module, squeeze-and-excitation 등 최신 기법의 아이디어를 논문을 통해 조사 후 적용
  -	MFCC, Spectrogram 등 다양한 음향 특징 추출 후 성능비교 실험 기획
- 프로젝트 성과
  -	화자 인증 시스템의 인식률을 48% 향상시키는 새로운 방법 제안 
  -	논문 작성 : [Improved RawNet with Filter-wise Rescaling for Text-independent Speaker Verification using Raw Waveforms](https://www.isca-speech.org/archive_v0/Interspeech_2020/pdfs/1011.pdf) 


## 어학 능력
- Korean (native)
- English (reading, writing: intermediate, speaking: basic)
- Japanese (speaking: intermediate, reading, writing: basic)

